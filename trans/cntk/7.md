# 第七章 LSTM 时间序列回归

时间序列回归问题的目标是基于历史时间数据进行预测。例如，如果您有一两年的月度销售数据，您可能希望预测下个月的销售情况。时间序列回归问题几乎总是极其困难的，你可以使用许多不同的技术。

![](../Images/image037.jpg)

图 7-1:使用神经网络的时间序列回归

图 7-1 中的截图显示了一个使用 LSTM(长短期记忆)深度神经网络的时间序列回归的例子。该数据是一个众所周知的国际航空公司每月乘客数量的数据集，从 1949 年 1 月到 1960 年 12 月。数据和最终预测模型如图 7-2 所示。

与本电子书中的其他示例不同，在时间序列回归中，特征/预测值和待预测类/值之间没有明显的区别。每个预测值都基于一个或多个先前的值。

区别有点微妙。在图 7-2 的图表中，第一个月的第一次乘客计数为 1.12 (112，000 名乘客)，第二个月的第二次乘客计数为 1.18。对于某些函数 f(t)，认为 f(1) = 1.12，f(2) = 1.18 等等是不正确的。每个乘客计数都是一系列值的一部分，而不是某种时间变量的显式函数。

![](../Images/image038.jpg)

图 7-2:实际与预测的时间序列回归

创建时间序列回归模型后，通常有两种使用方式。该模型可用于识别历史数据中的异常数据点，或者该模型可用于预测前面的一个或多个时间步长(有时称为外推)。在演示中，没有任何明显异常的数据点。1961 年 1 月的预测是 4.49 (449，000)名乘客。

## 准备航空公司乘客数据

航空公司乘客数据集似乎最早是由 Box 和 Jenkins 在 1976 年出版的书*时间序列分析:预测和控制*；然而，目前还不清楚作者是从哪里获得原始数据的。144 个项目的数据集可以在互联网上的许多地方以多种格式找到。

原始数据的一种形式是:

"1949-01";112
“1949-02”；118
“1949-03”；132
。。。

LSTM 时间序列回归演示程序使用滚动窗口技术，最好用例子来解释。演示使用的数据文件如下所示:

| prev 1.12 1.18 1.32 1.29 | next 1.21 | change 1.08035714
| prev 1.18 1.32 1.29 1.21 | next 1.35 | change 1.14406780
| prev 1.32 1.29 1.35 | next 1.48 | change 1.12121212

插入了`prev`、`next`和`change`标签，这样数据就可以很容易地被 CNTK `Reader`对象处理。四个连续数据点的每个序列被用作下一个数据点的预测集。这里输入序列的大小设置为 4。LSTM 的序列大小是一个自由参数，必须通过反复试验来确定。

每个原始乘客数都被除以 100，000，因此 1.12 表示 112，000 名乘客。几乎所有关于时间序列回归的问题都是棘手的；标准的 min-max 和 z-score 规范化通常无效。您可以在本电子书的附录中找到演示程序使用的完整数据集。

LSTM 没有直接预测下一次乘客数量。相反，模型预测相对于输入序列中第一项的变化因子。例如，第一组四个输入值为(1.12，1.18，1.32，1.29)，预测变化值为 1.08035714，这意味着下一个预测乘客数为 1.12 * 1.08035714 = 1.2100，如数据所示。`next`标签标识的数据项为 1.21，是原始的实际下一个计数。计算精度指标时，包含实际乘客计数值只是为了方便，模型预测的是变化系数，而不是计数。

格式化 144 个原始数据点后，有 140 个数据序列(前四项没有预测值)。请注意，设置滚动窗口数据会导致一些数据重复，因为大多数数据点会出现四次。另一种方法是只维护一个序列(在文件或内存中)，并以编程方式从该序列中读取。但是在大多数时间序列回归问题场景中，并没有大量的数据，所以使用重复数据的便利性往往超过了低效率。

## LSTM 网络

与常规神经网络不同，LSTM 网络保持状态。非正式地，LSTM 网络接受一个序列作为输入，并记住一点他们以前的输入和输出值。LSTM 网络是几种类型的递归神经网络之一。

LSTM 网络旨在处理自然语言数据。例如，假设你被要求预测句子中的下一个单词，“我在 _____ 上课。”没有任何背景，你很难做出准确的预测。但是假设你知道这一段的前一句话是，“我期待着我的西班牙之旅。”你可能会预测另一句话中的未知单词是“西班牙语”

我要强调的是，使用 LSTM 网络进行时间序列回归是推测性的，在撰写本电子书时，没有明确的研究结果表明 LSTM 网络的工作是否优于或劣于传统技术。然而，使用 LSTMs 进行时间序列回归似乎很有希望。此外，使用数字数据的 LSTM 网络比使用自然语言数据更容易，并为您提供了一个很好的 LSTMs 介绍。

碳纳米管库支持 LSTM 网络。LSTM 单元如图 7-3 所示。即使快速浏览一下这个数字也应该能让你相信 LSTMs 是复杂的，从头开始实施 LSTM 网络将是极具挑战性的。在图中，X <sub>t</sub> 向量表示四个连续的航空公司乘客计数的输入序列。Y <sub>t</sub> 向量代表四个输出值。为了计算输出值，LSTM 单元使用输入序列，加上先前的输出值(“短期”存储器)，加上保存所有先前输入和输出值信息的状态(“长期”存储器)。

![](../Images/image039.jpg)

图 7-3:LSTM 网络单元

LSTM 细胞的内部结构使用称为“门”的乙状结肠神经层来控制多少信息被记住，多少信息被遗忘。tanh 神经层保存状态信息。LSTM 细胞也使用向量乘法和加法。

## LSTM 时间序列回归程序

LSTM 时间序列回归程序代码如代码清单 7-1 所示。导入所需的 NumPy 和 CNTK 包后，演示程序定义了一个助手函数，用于将 CNTK 格式文件中的数据读取到一个小型批处理对象中:

def create_reader(path，input_dim，output_dim，rnd_order，sweeps):
x _ strm = c . io . stream def(field = ' prev '，shape=input_dim，is _ sparse = False)
y _ strm = c . io . stream def(field = ' next '，shape=output_dim，is_sparse=False)
streams = C .

注意`create_reader()`定义了三个流，而不是通常的两个流。没有必要定义对应于 CNTK 格式数据文件中每个标签的流。如果不打算在 CNTK 格式的数据文件中使用字段，可以通过不为该字段创建流来忽略该字段。

代码清单 7-1:时间序列回归

```
  #
  airline_lstm.py
  #
  time series regression with a CNTK LSTM

  import numpy as np
  import cntk as C

  #
  data resembles:
  #
  |prev 1.12 1.18 1.32 1.29 |next 1.21 |change 1.08035714
  #
  |prev 1.18 1.32 1.29 1.21 |next 1.35 |change 1.14406780

  def create_reader(path, input_dim,
  output_dim, rnd_order, sweeps):
    # rnd_order -> usually True for
  training
    # sweeps -> usually
  C.io.INFINITELY_REPEAT Or 1

  x_strm = C.io.StreamDef(field='prev',
  shape=input_dim, is_sparse=False)

  y_strm = C.io.StreamDef(field='change',
  shape=output_dim, is_sparse=False)

  z_strm = C.io.StreamDef(field='next', shape=output_dim,
  is_sparse=False)

  streams = C.io.StreamDefs(x_src=x_strm, y_src=y_strm, z_src=z_strm)

  deserial = C.io.CTFDeserializer(path, streams)

  mb_source = C.io.MinibatchSource(deserial, randomize=rnd_order,
  max_sweeps=sweeps)
    return mb_source

  def mb_accuracy(mb, x_var, y_var,
  model, delta):

  num_correct = 0

  num_wrong = 0

  x_mat = mb[x_var].asarray()  # batch_size x 1 x features_dim

  y_mat = mb[y_var].asarray()  # batch_size x 1 x 1

    for i in range(len(mb[x_var])):

  v = model.eval(x_mat[i])           # 1 x 1 predicted change factor

  y = y_mat[i]                       # 1 x 1 actual change factor

  if np.abs(v[0,0] - y[0,0]) < 
  delta:  # close enough?

  num_correct += 1

  else:

  num_wrong += 1
    return (num_correct * 100.0) / (num_correct + num_wrong)

  #
  ==================================================================================

  def main():
    print("\nBegin
  airline passenger time series regression LSTM \n")
    print("Using
  CNTK version = " +
  str(C.__version__) + "\n")

  train_file = ".\\Data\\airline_train_cntk.txt"

    # 1\. create model

  input_dim = 4   #
  context pattern window

  output_dim = 1  #
  passenger count increase/decrease factor

  X = C.ops.sequence.input_variable(input_dim)  # sequence of 4 items

  Y = C.ops.input_variable(output_dim)  # change from X[0]

  Z = C.ops.input_variable(output_dim)  # actual next passenger count

  model = None

  with C.layers.default_options():

  model = C.layers.Recurrence(C.layers.LSTM(shape=256))(X)

  model = C.sequence.last(model)

  model = C.layers.Dense(output_dim)(model)

    # 2\. create the learner and trainer

  learn_rate = 0.01

  tr_loss = C.squared_error(model, Y)  

  learner = C.adam(model.parameters, learn_rate, 0.99)

  trainer = C.Trainer(model, (tr_loss), [learner])

    # 3\. create the training reader;
  note rnd_order

  rdr = create_reader(train_file, input_dim, output_dim,

  rnd_order=True, sweeps=C.io.INFINITELY_REPEAT)

  airline_input_map = {

  X : rdr.streams.x_src, 

  Y : rdr.streams.y_src

  }

    # 4\. train

  max_iter = 20000

  batch_size = 10 

    print("Starting
  training \n")
    for i in range(0, max_iter):

  curr_mb = rdr.next_minibatch(batch_size, input_map=airline_input_map)

  trainer.train_minibatch(curr_mb)

  if i % int(max_iter/10) == 0:

  mcee = trainer.previous_minibatch_loss_average 

  acc = mb_accuracy(curr_mb, X, Y, model, delta=0.10)  # program-defined

  print("batch %6d: mean squared error = %8.4f  accuracy
  = %7.2f%%" \

  % (i, mcee, acc))
    print("\nTraining
  complete")

  mdl_name = ".\\Models\\airline_lstm.model"

  model.save(mdl_name)  #
  CNTK v2 format is default

    # 5\. compute model accuracy on data
    print("\nEvaluating
  LSTM model accuracy on test data with mb_acc() \n")

  rdr = create_reader(train_file, input_dim, output_dim,

  rnd_order=False, sweeps=1)

  airline_input_map = {

  X : rdr.streams.x_src,

  Y : rdr.streams.y_src

  # no need for Z at this
  point

  }

  num_items = 140

  all_items = rdr.next_minibatch(num_items, input_map=airline_input_map)

  acc = mb_accuracy(all_items, X, Y, model, delta=0.10)
    print("Prediction
  accuracy on the 140-item data set = %0.2f%%" % acc)

    # 6\. save actual-predicted values to
  make a graph later
    print("\nWriting
  actual-predicted pct values to file for graphing")

  fout = open(".\\Data\\actual_predicted_lstm.txt", "w")

  rdr = create_reader(train_file, input_dim, output_dim,

  rnd_order=False, sweeps=1)

  airline_input_map = {

  X : rdr.streams.x_src,

  Y : rdr.streams.y_src,

  Z : rdr.streams.z_src   #
  actual next passenger count

  } 

  num_items = 140

  all_items = rdr.next_minibatch(num_items, input_map=airline_input_map)

  x_mat = all_items[X].asarray()

  y_mat = all_items[Y].asarray()

  z_mat = all_items[Z].asarray()

    for i in range(all_items[X].shape[0]):  # each item in the batch

  v = model.eval(x_mat[i])           # 1 x 1 predicted change

  y = y_mat[i]                       # 1 x 1 actual change

  z = z_mat[i]                       # actual next count

  x = x_mat[i]                       # first item in sequence

  p = x[0,0] * v[0,0]                # predicted next count

  fout.write("%0.2f,
  %0.2f\n" %
  (z[0,0], p))

  fout.close()

    # 7\. predict passenger count for
  Jan. 1961

  np.set_printoptions(precision = 4, suppress=True)

  in_seq = np.array([[5.08, 4.61, 3.90, 4.32]], dtype=np.float32)  # last 4 actual
    print("\nForecasting
  passenger count for Jan. 1961 using: ")
    print(in_seq[0])

  pred_change = model.eval({X: in_seq})   
    print("\nForecast
  change factor is: ")
    print("%0.6f
  " %
  pred_change[0,0])

  pred_count = in_seq[0,0] * pred_change[0,0]
    print("Forecast
  passenger count = %0.4f" % pred_count)

    print("\nEnd
  demo \n")

  #
  ==================================================================================

  if __name__ == "__main__":

  main()

```

因为演示 LSTM 网络的输出是一个数值，所以如果想要测量精度，就需要实现一个自定义的精度函数。演示程序定义了一个函数`mb_accuracy()`(“小批量精度”)，在给定小批量输入和输出值的情况下，该函数计算正确输出值的百分比，并定义了一个模型来计算预测输出值:

def mb_accuracy(mb，x_var，y_var，model，delta):
num _ correct = 0；num _ error = 0
x _ mat = MB[x _ var]。asar ray()# batch _ size x 1 x features _ dim
y _ mat = MB[y _ var]。asarray() # batch_size x 1 x 1
为 I in range(len(MB[x _ var]):
v = model . eval(x _ mat[I])# 1 x 1 预测变化系数
y = y_mat[i] # 1 x 1 实际变化系数
如果 np.abs(v[0，0] - y[0，0])<δ:#足够接近？
num _ correct+= 1
else:
num _ error+= 1
return(num _ correct * 100.0)/(num _ correct+num _ error)

回想一下，LSTM 网络预测的是一个变化因素，而不是乘客数量。因此，精度函数基于预测的变化系数而不是预测的乘客数量来计算精度。数据文件中的下个月实际乘客计数值根本没有使用。

在`main()`功能中，演示程序准备用以下语句创建 LSTM 模型:

train_file =。\ \ Data \ \ airline _ train _ cntk . txt "

input _ dim = 4 #上下文模式窗口
output_dim = 1 #乘客数量增加/减少因子
X = c . ops . sequence . input _ variable(input _ dim)# 4 个项目的序列
Y = c . ops . input _ variable(output _ dim)# pct 从 X[0]
Z = c . ops . input _ variable(output _ dim)#实际下一个乘客数量

每个输入序列中的值的数量被设置为 4。LSTMs 可以处理可变大小的输入序列。在处理自然语言(例如句子长度)时，这种序列经常出现。但是对于数字数据，固定的序列/窗口大小更常见。

使用 LSTM 时，不是使用`cntk.ops.input_variable()`功能创建输入`Variable`对象，而是使用`cntk.ops.sequence.input_variable()`功能创建特殊的`Variable`对象。

LSTM 网络单元是这样创建的:

模型=无
带 C.layers.default_options():
模型= c . layers . recursion(c . layers . LSTM(shape = 256))(X)
模型= C.sequence.last(模型)
模型= c . layers . density(output _ dim)(模型)

在`Recurrence`层内创建一个 LSTM 单元，这样它的输出值和状态作为输入被反馈，如图 7-3 所示。`LSTM()`的`shape=256`参数是状态输出的大小和记住先前输入和输出值的内部 tanh 层。这个参数不是直接传递一个整数，而是作为一个变量间接传递，命名为`hidden_dim`。

粗略地说，`shape`参数的较大值意味着 LSTM 记得更多，但这不一定总是一件好事。对于时间序列回归，网络可能不会从记忆过去很久的输入模式中受益。

句法上需要使用`sequence.last()`功能。`last()`函数返回 LSTM 单元中的最后一个状态输出(256 个值)，因为只需要输入序列集生成的最后一个状态。

LSTM 网络通常使用丢弃层，该丢弃层在训练期间随机丢弃节点，以降低模型过拟合的可能性。演示不使用辍学。

网络中的最后一层是标准的`Dense`层，它添加了一个最终节点，并将 256 个最终状态值浓缩为一个值。从技术上来说，这并不是完全必要的，但是增加一个额外的层会增加额外的权重和额外的偏差值，这在理论上给了模型更多的预测能力。

您可以添加多个`Dense`层，例如:

模型= c . layers . recursion(c . layers . lstm(shape = 256))(X)
模型= C.sequence.last(模型)
模型= C.layers.Dense(10)(模型)
模型= C.layers.Dense(output_dim)(模型)

您可以添加额外的`Recurrence`层，例如:

模型= c . layers . recursion(c . layers . lstm(shape = 256))(X)
模型= c . layers . recursion(c . layers . lstm(shape = 256))(模型)
模型= C.sequence.last(模型)
模型= C.layers.Dense(output_dim)(模型)

对奇异的 LSTM 网络结构知之甚少，研究这些结构是深度神经网络研究的一个活跃领域。

## 训练一个 LSTM 网络

创建 LSTM 网络后，以通常的方式创建`Learner`和`Trainer`对象:

learn_rate = 0.01
tr_loss = C . square _ error(model，Y)
leader = C . Adam(model . parameters，learn _ rate，0.99)
Trainer = C . Trainer(model，(tr _ loss)，【leaner】)

根据经验，随着网络架构规模和复杂性的增加，更重要的高级`Learner`算法变得越来越重要。演示使用 Adam(自适应矩估计)学习器，这是在使用 LSTM 网络时的一个很好的第一次尝试。0.99 参数被分配给`adam()`函数的`momentum`参数，但是有点混乱的是被 CNTK 文档描述为`beta1`参数。当没有默认值时，为高级学习函数选择合理的值需要研究、反复试验和耐心。

演示程序为时间序列训练数据创建了一个阅读器，如下所示:

rdr = create_reader(train_file，input_dim，output_dim，
rnd_order=True，sweeps = c . io . infinity _ REPEAT)
T2】航空公司 _ input _ map = {
X:rdr . streams . X _ src，
Y : rdr.streams.y_src
}

使用`rnd_order=True`调用`create_reader()`函数，这意味着每一批训练项目将按照随机顺序进行处理。这似乎违反直觉，因为训练数据是一个大的价值序列。在与我的同事的讨论中，关于训练数据应该以随机顺序处理还是以顺序处理，意见大致上各占一半。正如简单神经网络刚出现时(1980 年代)的情况一样，许多关于 LSTM 网络的基本概念目前还没有被很好地理解。

时间序列回归的 LSTM 网络的实际训练是通过以下语句进行的:

max _ ITER = 20000
batch _ size = 10
打印(开始训练\ n)
I in range(0，max _ ITER):
curr _ MB = rdr . next _ minibatch(batch _ size，input _ map = airline _ input _ map)
train _ minibatch(curr _ MB)
if I % int(max _ ITER/10)= = 0:
mcee = trainer . previous _ minibatch _ loss _ loss\ \ Models \ \ airline _ lstm . model "
model . save(MDL _ name)#默认为 CNTK v2 格式

典型地，训练 LSTM 网络比训练单个隐藏层神经网络需要更多的训练迭代。监控培训期间的错误/损失至关重要，因为根据我的经验，在与 LSTM 网络合作时，培训失败是常态而非例外。演示在训练过程中打印错误 10 次:`int(max_iter/10)`。

演示程序在训练完成后保存训练好的模型(使用默认的 CNTK v2 格式)。另一种方法是在训练过程中保存中间模型，偶尔保存一次。例如，在上面代码中的`if`条件内，您可以编写:

mdl_name =。\ \ Models \ \ airline _ lstm _“+str(I)+”。模型"
model.save(mdl_name)

除了将训练迭代嵌入到中间模型名称中，您还可以嵌入信息，例如与模型相关的丢失/错误。关键是，对于非演示数据集，训练可能需要几个小时或几天，而保存中间模型在实践中是必要的。CNTK 支持的检查点机制超出了本电子书的范围。

当前一批 10 个训练项目的平均模型精度经常被打印出来。训练后，演示程序还使用程序定义的`mb_accuracy()`函数计算并打印整个 140 项数据集的模型精度。在非演示场景中，您可能还希望计算并打印整个数据集的平均损失/误差。例如，您可以编写一个程序定义的函数:

def mb_error(mb，x_var，y_var，model):
sum _ sq _ err = 0.0
x _ mat = MB[x _ var]。asar ray()# batch _ size x 1 x features _ dim
y _ mat = MB[y _ var]。asarray() # batch_size x 1 x 1
适用于范围内的 I(len(MB[x _ var]):
v = model . eval(x _ mat[I])# 1 x 1 预测变化系数
y = y_mat[i] # 1 x 1 实际变化系数
sum_sq_err += (v[0，0] - y[0，0]) * (v[0，0] - y[0，0])
返回 sum_sq_err / len(mb[x

尝试使用`Trainer`对象的内置`previous_minibatch_loss_average`属性可能是一个错误，因为您必须调用`train()`方法，该方法将修改训练好的模型。

## 预测和预报

当执行时间序列回归时，绘制结果图几乎总是有用的。训练后，演示 LSTM 程序遍历 140 个项目的训练数据，计算预测乘客数量，然后将实际数量和预测数量对写入文本文件。

首先，程序准备分析:

打印(" \ n 将实际-预测的乘客人数记录到文件中以便绘图")
fout = open(。\ \ Data \ \ actual _ predicted _ lstm . txt，" " w ")
rdr = create _ reader(train _ file，input_dim，output_dim，
rnd_order=False，sweeps = 1)
airline _ input _ map = {
X:rdr . streams . X _ src，
Y : rdr.streams.y_src，
Z : rdr.streams.z_src #实际下一次乘客人数
}
num_items = 140

尽管 LSTM 网络模型预测的是变化因素而不是直接的乘客数量，但是绘制实际预测的乘客数量比绘制实际预测的变化值更有意义(尽管两者都可以绘制)。

演示程序不是根据实际变化系数和输入序列的第一个值计算实际乘客计数，而是读取实际计数，为了方便起见，这些计数存储在训练数据文件中。注意`Reader`对象的输入映射设置了所有三个数据流。接下来，演示程序将输入序列、实际变化和实际下一次计数数据提取到三个矩阵中:

x_mat = all_items[X]。asar ray()
Y _ mat = all _ items[Y]。asar ray()
Z _ mat = all _ items[Z]。asarray()

回想一下`all_items`是一个实现为字典对象的 CNTK 小批量对象，`X`、`Y`、`Z`、`Variable`对象作为关键字。接下来，处理每个项目:

对于范围内的 I(all _ items[X]。shape[0]): #批次中的每个项目
v = model.eval(x_mat[i]) # 1 x 1 预测变化
y = y_mat[i] # 1 x 1 实际变化
z = z_mat[i] #实际下一个计数
x = x_mat[i] #序列中的第一个项目
p = x[0，0] * v[0，0] #预测下一个计数
fout.write("%0.2f，%0.2f\n" %)

error.close（）

`eval()`功能将预测的变化值计算到`v`中，因此预测的乘客数量是当前序列`x[0,0]`乘以`v[0,0]`的第一项，因为两个值都返回到 1 1 矩阵中。在实践中，您将花费大量时间使用`shape`属性和`print()`函数来确定不同 CNTK 对象的形状。

每个实际预测的逗号分隔对都被写入指定的文本文件。另一种方法是使用`append()`或`insert()`函数将实际预测的对存储到 Python 列表中。

将实际预测的数据写入文本文件后，我用 Excel 打开文件，创建了如图 7-2 所示的图形。另一种方法是使用 Python `matplotlib`包从脚本中以编程方式创建一个图形。许多 CNTK 文档示例都使用这种方法。然而，`matplotlib`代码可能会模糊 CNTK 模型创建、训练和评估的主要思想，所以我使用了一种外部技术来创建图形。

在时间序列回归中，对训练数据中超出输入值范围的输入值进行预测通常称为预测或外推。演示程序预测训练数据之后的第一个时间段(1961 年 1 月，第 141 个月)的变化，然后使用该变化计算预测的下一次乘客数量:

in_seq = np.array([[5.08，4.61，3.90，4.32]]，dtype=np.float32) #最后 4 个实际
打印(" \ n 为 1961 年 1 月的旅客人数使用:")
打印(in _ seq[0])
pred _ change = model . eval({ X:in _ seq })
打印(" \ n 为 1961 年 1 月的旅客人数使用:")
打印(" % 0.6f " % pred

`in_seq` 1 4 阵列保存最后四个标准化的实际乘客计数。该数组通过`X`键传递给`eval()`函数，以创建一个匿名字典对象。数组可能是直接传递的。返回值是一个 1 1 矩阵，保存预测的变化。该变化值乘以输入序列中的第一项，以确定预测的乘客数量。

在很多情况下，你只想提前预测一个时间单位。但是，您可以根据自己的意愿推断任意多的时间单位。代码清单 7-2 中的短程序推断出 8 个时间单位超过了训练数据。

代码清单 7-2:推断时间序列

```
  #
  airline_forecast_lstm.py
  #
  CNTK v2.3 Ananconda 4.1.1

  import numpy as np
  import cntk as C

  model
  = C.ops.functions.Function.load(".\\Models\\airline_lstm.model")

  np.set_printoptions(precision = 2,
  suppress=True)
  curr
  = np.array([[5.08, 4.61, 3.90, 4.32]],
  dtype=np.float32)

  for i in
  range(8):

  pred_change = model.eval(curr)

  print("\nCurrent
  counts : ", end=""); print(curr)

  print("Forecast
  change factor = %0.4f" % pred_change[0,0])

  pred_count = curr[0,0] * pred_change[0,0]

  print("Forecast
  passenger count = %0.2f" % pred_count)

    for j in range(3):

  curr[0,j] = curr[0,j+1]

  curr[0,3] = pred_count

```

如图 7-2 中的图表所示，在外推时间序列数据时必须非常小心，因为预测的准确性通常会迅速下降。

## 运动

本电子书的附录中有 2005 年 1 月至 2014 年 12 月华盛顿金县(西雅图地区)每月初始失业申请的原始数据。使用代码清单 7-1 中的程序作为指南，创建一个 LSTM 时间序列回归模型。

原始数据来自这里的。

原始逗号分隔数据有 120 项，看起来像:

8/1/2007，6110
9/1/2007，5298
。。。
2014 年 1 月 11 日，6993
2014 年 1 月 12 日，7978

您必须决定如何规范化数据，以及如何设置 CNTK 格式的数据文件。我建议使用 Excel 或类似的电子表格对原始数据进行预处理。