# 第 2 章多类分类

多类分类的目标是进行预测，其中要预测的变量可以采用一组三个或更多离散值中的一个。例如，您可能希望根据一个人(民主党人、共和党人或其他人)的年龄、性别、年收入等来预测他们的政党归属。

![](../Images/image022.jpg)

图 2-1:使用 Keras 的多类分类

图 2-1 中的截图展示了多类分类的演示。演示程序首先将 120 个训练数据项和 30 个测试数据项加载到内存中。每个项目代表一朵鸢尾花，其中四个预测变量是萼片长度、萼片宽度、花瓣长度和花瓣宽度(萼片是一种叶子状的结构)。要预测的变量是`species`。有三种可能的物种:`setosa`、`versicolor`和`virginica`。

在幕后，演示程序创建了一个 4-(5-6)-3 神经网络，即一个具有四个输入值(每个预测变量一个)，两个分别具有五个和六个节点的隐藏层，以及三个输出节点(每个可能的物种一个)。演示程序使用 10 个时期来训练神经网络模型。

训练完成后，训练后的模型对测试数据的预测准确率达到 100.00%(30 对 30 正确)。演示最后用预测值(6.1，3.1，5.1，1.1)对一种新的、以前未见过的鸢尾花进行了预测。预测概率为(0.0172，0.7159，0.2669)，由于第二个值最大，预测为`versicolor`。

## 理解数据

Fischer 的 Iris 数据集是统计学和机器学习领域最著名的基准数据集之一。总共有 150 个项目。原始数据如下所示:

`5.1, 3.5, 1.4, 0.2, setosa
7.0, 3.2, 4.7, 1.4, versicolor
6.3, 3.3, 6.0, 2.5, virginica`

原始数据是通过对类标签进行一次性编码来准备的，但是特征值并没有像通常所做的那样标准化:

`5.1, 3.5, 1.4, 0.2, 1, 0, 0
7.0, 3.2, 4.7, 1.4, 0, 1, 0
6.3, 3.3, 6.0, 2.5, 0, 0, 1`

编码后，整个数据集被分成 120 个项目的训练集和 30 个项目的测试集，在训练后用于模型评估。因为数据有四个维度，所以不可能在二维图中轻松地可视化它，但是您可以从图 2-2 中的部分图中大致了解数据。

![](../Images/image023.jpg)

图 2-2:虹膜数据

如图所示，虹膜数据集几乎太简单了。类`setosa`很容易与`versicolor`和`virginica`区分开来。此外，类`versicolor`和`virginica`几乎是线性可分的。然而，虹膜数据集是一个简单的例子。

顺便说一句，实际上至少有两种不同版本的费希尔虹膜数据是通用的。最初的数据是在 1935 年收集的，然后由费舍尔在 1936 年发表。然而，在某个时间点上，`setosa`项的一些原始值被错误地复制，几年后它们进入了互联网。这并不严重，因为数据集现在只用于教学示例，而不是严肃的研究。

## 艾瑞斯项目

代码清单 2-1 显示了生成图 2-1 所示输出的完整程序。该程序首先对程序文件名以及所使用的 Python、TensorFlow 和 Keras 版本进行注释，然后导入 NumPy、Keras、TensorFlow 和 OS 包:

`# iris_dnn.py
# Python 3.5.2, TensorFlow 2.1.5, Keras 1.7.0
import numpy as np
import keras as K
import tensorflow as tf
import os
os.environ['TF_CPP_MIN_LOG_LEVEL']='2'`

在非演示场景中，您可能希望在注释中包含更多细节。因为 Keras 和 TensorFlow 正在快速发展，所以您应该始终记录正在使用的版本。在使用 Keras 和其他开源软件时，版本不兼容可能是一个严重的问题。

代码清单 2-1:虹膜多类分类程序

```
  #
  iris_dnn.py
  #
  Python 3.5.2, TensorFlow 2.1.5, Keras 1.7.0

  #
  ==================================================================================

  import numpy as np
  import keras as K
  import tensorflow as tf
  import os
  os.environ['TF_CPP_MIN_LOG_LEVEL']='2'

  def main():
    # 0\. get started

  print("\nIris
  dataset using Keras/TensorFlow ")
    np.random.seed(4)
    tf.set_random_seed(13)

    # 1\. load data

  print("Loading
  Iris data into memory \n")

  train_file = ".\\Data\\iris_train.txt"

  test_file = ".\\Data\\iris_test.txt"

  train_x = np.loadtxt(train_file,
  usecols=[0,1,2,3],

  delimiter=",",  skiprows=0, dtype=np.float32)

  train_y = np.loadtxt(train_file,
  usecols=[4,5,6],

  delimiter=",", skiprows=0, dtype=np.float32)

  test_x = np.loadtxt(test_file, usecols=range(0,4),

  delimiter=",",  skiprows=0, dtype=np.float32)

  test_y = np.loadtxt(test_file, usecols=range(4,7),

  delimiter=",", skiprows=0, dtype=np.float32)

    # 2\. define model

  init = K.initializers.glorot_uniform(seed=1)

  simple_adam = K.optimizers.Adam()

  model = K.models.Sequential()

  model.add(K.layers.Dense(units=5, input_dim=4,
  kernel_initializer=init,

  activation='relu'))

  model.add(K.layers.Dense(units=6,
  kernel_initializer=init,

  activation='relu'))

  model.add(K.layers.Dense(units=3,
  kernel_initializer=init,

  activation='softmax'))

  model.compile(loss='categorical_crossentropy', 

  optimizer=simple_adam, metrics=['accuracy'])

    # 3\. train model

  b_size = 1

  max_epochs = 10

  print("Starting
  training ")

  h = model.fit(train_x, train_y, batch_size=b_size, epochs=max_epochs,

  shuffle=True, verbose=1) 

  print("Training
  finished \n")

    # 4\. evaluate model

  eval = model.evaluate(test_x, test_y, verbose=0)

  print("Evaluation
  on test data: loss = %0.6f  accuracy = %0.2f%% \n" \

  % (eval[0], eval[1]*100) )

    # 5\. save model

  print("Saving
  model to disk \n")

  mp = ".\\Models\\iris_model.h5"

  model.save(mp)

    # 6\. use model
    np.set_printoptions(precision=4)

  unknown = np.array([[6.1, 3.1, 5.1, 1.1]],
  dtype=np.float32)

  predicted = model.predict(unknown)

  print("Using
  model to predict species for features: ")

  print(unknown)

  print("\nPredicted
  species is: ")

  print(predicted)

  #
  ==================================================================================

  if __name__=="__main__":

  main()

```

程序导入整个 Keras 包并分配一个别名`K`。另一种方法是只导入您需要的模块，例如:

`from keras.models import Sequential
from keras.layers import Dense, Activation`

即使 Keras 使用 TensorFlow 作为其后端引擎，您也不需要显式导入 TensorFlow，只需设置其随机种子即可。导入操作系统包只是为了抑制恼人的 TensorFlow 启动警告消息。

程序结构由一个主函数组成，没有辅助函数。该计划始于:

`def main():
# 0\. get started
print("\nIris dataset using Keras/TensorFlow ")
np.random.seed(4)
tf.set_random_seed(13)

# 1\. load data
print("Loading Iris data into memory \n")
train_file = ".\\Data\\iris_train.txt"
test_file = ".\\Data\\iris_test.txt"
. . .`

在大多数情况下，你希望你的结果是可复制的。Keras 库广泛使用了 NumPy 全局随机数生成器，因此设置种子值是一个很好的做法。程序中使用的值`4`是任意的。同样，因为 Keras 使用 TensorFlow，所以您通常也想要设置它的种子。然而，由于并行任务的数值舍入顺序，程序结果通常不完全可再现。

由于页面宽度的限制，我用两个空格而不是通常的四个空格来缩进。所有正常的错误检查都被删除了，以保持主要思想尽可能清晰。

程序假设训练和测试数据文件位于名为`Data`的子目录中。该程序没有任何关于数据文件结构的信息。我强烈建议您包括计划注释，例如:

`# data is comma-delimited and looks like:
# 5.1, 3.5, 1.4, 0.2, 1, 0, 0
# first four values are non-normalized features
# last three values are one-hot labels for
# setosa, versicolor, virginica
# 120 training items, 30 test items`

这种信息在你写程序的时候很容易记住，但是几周后就很难记住了。

训练和测试数据通过以下语句读入内存:

`train_x = np.loadtxt(train_file, usecols=[0,1,2,3],
delimiter=",", skiprows=0, dtype=np.float32)
train_y = np.loadtxt(train_file, usecols=[4,5,6],
delimiter=",", skiprows=0, dtype=np.float32)

test_x = np.loadtxt(test_file, usecols=range(0,4),
delimiter=",", skiprows=0, dtype=np.float32)
test_y = np.loadtxt(test_file, usecols=range(4,7),
delimiter=",", skiprows=0, dtype=np.float32)`

一般来说，Keras 需要将特征数据和标签数据存储在单独的 NumPy 阵列样式矩阵中。将数据读入内存的方法有很多，但`loadtxt()`功能的通用性足以满足大多数问题场景。NumPy `genfromtxt()`函数非常相似，但是它给了你一些额外的选项，比如处理丢失的数据。`loadtxt()`功能参数很多，但大多数情况下，你只需要`usecols`、`delimiter`和`dtype`。

注意`usecols`可以接受`[0,1,2,3]`这样的列表或者`range(0,4)`这样的 Python 范围。如果使用`range()`功能，注意记住第一个参数是包含的，第二个参数是排他的。

除了逗号字符外，`delimiter`参数的常用值是“\t”(制表符)和“”(单个空格)默认参数值是`None`，表示任何空格。

默认`dtype`参数值为`numpy.float`，是 Python `float`的别名，与`numpy.float64`完全相同。但是几乎所有 Keras 函数的默认数据类型都是`numpy.float32`，所以程序指定了这种类型。这个想法是，对于大多数机器学习问题，使用 64 位值获得的精度优势不值得内存和性能损失。

使用静态、独立的训练和测试文件的另一种方法是只使用一个包含所有数据的文件，将所有数据读入内存，然后在内存中以编程方式生成训练和测试矩阵。这种替代技术允许您执行 k 倍交叉验证，这种技术过去很常见，但现在很少用于深度学习和非常大的数据集。

不同于使用诸如`loadtxt()`这样的 NumPy 函数将数据读入内存，一种不同的方法是使用 Pandas(最初是“面板数据”，现在是“Python 数据分析库”)库，该库具有许多高级数据操作功能。然而，熊猫有一个显著的学习曲线。

## 定义神经网络模型

该程序使用以下代码定义了一个 4-(5-6)-3 深度神经网络:

`# 2\. define model
init = K.initializers.glorot_uniform(seed=1)
simple_adam = K.optimizers.adam()
model = K.models.Sequential()
model.add(K.layers.Dense(units=5, input_dim=4, kernel_initializer=init,
activation='relu'))
model.add(K.layers.Dense(units=6, kernel_initializer=init,
activation='relu'))
model.add(K.layers.Dense(units=3, kernel_initializer=init,
activation='softmax'))`

`model.compile(loss='categorical_crossentropy',
optimizer=simple_adam, metrics=['accuracy'])`

深度神经网络通常对权重和偏差的初始值非常敏感，因此 Keras 有几种不同的初始化函数。演示使用`glorot_uniform()`，它根据使用它的网络层的扇入和扇出分配小的随机值。使用`seed`参数，以便程序结果可再现。表 2-1 列出了 Keras 中一些常见的初始化函数。

表 2-1:常用函数

| **功能** | **描述** |
| --- | --- |
| `Zeros()` | 所有`np.float32` `0.0`值 |
| `Constant(value=0)` | 所有单个指定的`np.float32` 值 |
| `RandomNormal(mean=0.0, stddev=0.05, seed=None)` | 高斯钟形分布 |
| `RandomUniform(minval=-0.05, maxval=0.05, seed=None)` | 随机，均匀分布在 minval 和`maxval`之间 |
| `glorot_normal(seed=None)` | 用`stddev = sqrt(2 / (fan_in + fan_out))`截断`Normal` |
| `glorot_uniform(seed=None)` | 带限制的均匀随机`sqrt(6 / (fan_in + fan_out))` |

该程序准备一个`Adam()`优化器对象供`fit()`训练函数使用。Adam(自适应矩估计)是 Keras 支持的众多训练算法之一，在创建预测模型时是很好的首选。该程序使用所有`Adam()`默认参数，但它们可以作为一种文档形式明确指定:

`simple_adam = K.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999,
epsilon=None, decay=0.0, amsgrad=False) # default parameter values`

程序使用`Sequential()`方法建立神经网络结构。输入层是隐式的，因此模型从第一个隐藏层开始:

`model = K.models.Sequential()
model.add(K.layers.Dense(units=5, input_dim=4, kernel_initializer=init,
activation='relu'))`

`Dense()`功能是一个标准的全连接层。`units`参数指定图层中隐藏处理节点的数量，由于这是列出的第一个图层，因此必须使用`input_dim`参数指定有多少个输入值。

隐藏层配置为使用`relu`激活(整流线性单位)。正如您所料，Keras 支持许多激活功能。对于一个`Dense()`隐藏层来说，`relu`往往是不错的第一次尝试。表 2-2 列出了其他常见的激活功能。Keras 还包含高级的自适应激活功能，如`keras.layers`模块中的`LeakyReLU()`。

表 2-2:常见的密集层激活函数

| **功能** | **描述** |
| --- | --- |
| `relu(x, alpha=0.0, max_value=None)` | 如果 x < 0，f(x) = 0，否则 f(x) = x |
| `tanh(x)` | 双曲正切 |
| `sigmoid(x)` | f(x) = 1.0 / (1.0 + exp(-x)) |
| `linear(x)` | f(x) = x |
| `softmax(**x**, axis=-1)` | 强制向量 **x** 的值相加为 1.0，这样它们可以被松散地解释为概率 |

为`Dense()`函数的激活参数提供类似`'relu'`的字符串值(在`relu()`和`softmax()`的情况下使用默认参数值)的替代方法是使用`Activation`图层。例如:

`model = K.models.Sequential()
model.add(K.layers.Dense(units=5, input_dim=4, kernel_initializer=init))
model.add(K.layers.Activation('relu'))`

与 Keras 合作的挑战之一是，随着时间的推移，它已经发展了许多不同的技术，这可能会令人困惑。有时，较旧的示例使用一种方法，例如单独的`Activation`层，而较新的示例使用不同的方法，例如`Dense()`中的字符串`activation`参数。

在设置了隐含的输入层和显式的第一个隐藏层之后，架构的其余部分是这样指定的:

`model.add(K.layers.Dense(units=6, kernel_initializer=init,
activation='relu'))
model.add(K.layers.Dense(units=3, kernel_initializer=init,
activation='softmax'))`

因为这两者都不是第一层，所以您不必指定输入值的数量。如果你愿意，你可以这样做:

`model.add(K.layers.Dense(units=6, input_dim=5, kernel_initializer=init,
activation='relu'))
model.add(K.layers.Dense(units=3, input_dim=6, kernel_initializer=init,
activation='softmax'))`

不使用`Sequential()`和`add()`方法，您可以通过创建单独的层来构建神经网络，然后将它们传递给`Model()`构造器，如下所示:

`init = K.initializers.glorot_uniform(seed=1)
X = K.layers.Input(shape=(4,))
net = K.layers.Dense(units=5, kernel_initializer=init,
activation='relu')(X)
net = K.layers.Dense(units=6, kernel_initializer=init,
activation='relu')(net)
net = K.layers.Dense(units=3, kernel_initializer=init,
activation='softmax')(net)
model = K.models.Model(X, net)`

这两种方法创建了完全相同的神经网络，但在语法方面有很大不同。对于多类分类问题，选择纯粹是个人偏好。

定义了神经网络模型后，必须对其进行编译，然后才能对其进行训练:

`model.compile(loss='categorical_crossentropy',
optimizer=simple_adam, metrics=['accuracy'])`

你可以粗略地把编译过程想象成把 Keras 代码翻译成 TensorFlow 代码(或者 CNTK 代码或者 antano 代码)。您必须将值传递给`optimizer`和`loss`参数，以便`fit()`方法知道如何训练模型。对于多类分类来说，`categorical_crossentropy`损失函数通常是最好的选择，但是如果需要，您可以使用`mean_squared_error`函数(例如，复制其他人的工作)。

`metrics`参数是可选的。程序传递一个只包含`'accuracy'`的 Python 列表，以指示应该在训练期间计算分类精度(正确预测的百分比)。

## 培训和评估模型

将训练数据读入存储器并创建神经网络后，程序使用以下语句训练模型:

`# 3\. train model
b_size = 1
max_epochs = 10
print("Starting training ")
h = model.fit(train_x, train_y, batch_size=b_size, epochs=max_epochs,
shuffle=True, verbose=1)
print("Training finished \n")`

批量设置为`1`，称为在线培训。这意味着每个训练项目的神经网络权重和偏差都会更新。替代方法是将批次大小设置为训练集中的项目数(120)，这有时被称为全批次训练，或者将批次大小设置为中间值，如`16`，这被称为小批次训练。

`max_epochs`变量控制将用于训练的迭代次数。`fit()`功能中的`shuffle`参数表示训练项目应该随机处理。默认值为`True`，因此该参数可以省略。`verbose`参数控制训练时显示多少信息:`0`表示不显示信息，`1`表示显示全部信息，`2`表示显示中等信息量。

`fit()`函数返回一个记录了训练历史的字典对象。演示程序将这些信息捕获到对象`h`中，但没有利用它。如果您想查看损失值，可以这样做:

`print(h.history['loss'])`

培训后，演示程序根据测试数据评估模型:

`# 4\. evaluate model
eval = model.evaluate(test_x, test_y, verbose=0)
print("Evaluation on test data: loss = %0.6f accuracy = %0.2f%% \n" \
% (eval[0], eval[1]*100) )`

`evaluate()`函数返回一个值列表。索引`[0]`处的第一个值始终是在`compile()`函数中指定的所需损失函数的值。列表中的其他值是来自`compile()`功能的任意可选`metrics`。在本例中，通过了`'accuracy'`，因此索引`[1]`处的值保持分类精度。该程序乘以 100，将精度从比例(如 0.9123)转换为百分比(如 91.23%)。

## 保存和使用模型

在大多数情况下，你会想要保存一个训练好的模型，尤其是如果训练花费了几个小时甚至更长的时间。演示程序将训练好的模型保存如下:

`# 5\. save model
print("Saving model to disk \n")
mp = ".\\Models\\iris_model.h5"
model.save(mp)`

有点不同寻常的是，与其他神经网络库相比，Keras 使用分层数据格式(HDF)版本 5 保存了一个训练好的模型。它是二进制格式，所以保存的模型不能用文本编辑器检查。除了保存整个模型，您还可以只保存模型权重和偏差，这有时很有用。您还可以保存公正的模型架构，但不能保存权重。

可以从不同的程序加载保存的 Keras 模型，如下所示:

`print("Loading a saved model")
mp = ".\\Models\\iris_model.h5"
model = K.models.load_model(mp)`

创建和训练模型的全部意义在于，它可以用来预测新的、以前看不到的数据:

`# 6\. use model
np.set_printoptions(precision=4)
unknown = np.array([[6.1, 3.1, 5.1, 1.1]], dtype=np.float32)
predicted = model.predict(unknown)
print("Using model to predict species for features: ")
print(unknown)
print("\nPredicted species is: ")
print(predicted)`

`predict()`方法接受输入，并根据模型当前权重和偏差的值计算输出。请注意，变量`unknown`是一个数组数组(由双方括号表示)，而不是一个简单的向量。

输出是原始的，因为它是一组概率。由你来解释意思。您可以按照以下方式通过编程实现:

`labels = ["setosa", "versicolor", "virginica"]
idx = np.argmax(predicted)
species = labels[idx]
print(species)`

`argmax(v)`函数返回向量或列表中最大值的索引`v`。它是许多分类问题的有用函数。

## 摘要和资源

要执行多类分类，您可以使用一个热点(也称为 1/N)编码对目标标签进行编码。输出层上的激活函数应该设置为`softmax`，这样节点值总和为 1.0，可以松散地解释为概率。

损耗功能在大多数情况下应该设置为`categorical_crossentropy`，但如果你愿意，也可以使用`mean_squared_error`。一般来说，您应该将`accuracy`传递给`compile()`功能的可选`metrics`列表。

多类分类的自由参数包括隐藏层数和每个隐藏层中的节点数、`optimizer`算法(但`Adam`往往是一个不错的选择)、批量大小以及要使用的最大训练时期数。

演示程序使用的训练和测试数据可以在[这里](https://github.com/jdmccaffrey/keras-succinctly/tree/master/Iris)找到。

演示程序使用`glorot_uniform()`功能进行初始化。参见此处的附加信息和备选方案[。](https://keras.io/initializers/)

演示程序使用`relu()`功能进行隐藏层激活。参见此处的附加信息和备选方案[。](https://keras.io/activations/)